{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import lit,to_timestamp, coalesce, col, date_format, when\n",
    "from functools import reduce\n",
    "import csv\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define la ruta base\n",
    "base_path = Path(\"/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS\")\n",
    "\n",
    "# Lista 1: Archivos .csv que contienen \"AQ_SEP\" en su nombre\n",
    "lista_aq_sep = [archivo for archivo in base_path.rglob(\"*.csv\") if \"AQ_SEP\" in archivo.name]\n",
    "\n",
    "# Lista 2: Archivos .csv que contienen \"AirQualityUnit01\" en su nombre\n",
    "lista_airqualityunit01 = [archivo for archivo in base_path.rglob(\"*.csv\") if \"AirQualityUnit01\" in archivo.name]\n",
    "\n",
    "# Lista 3: Archivos .csv que contienen \"AirQualityUnit02\" en su nombre\n",
    "lista_airqualityunit02 = [archivo for archivo in base_path.rglob(\"*.csv\") if \"AirQualityUnit02\" in archivo.name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos con 'AQ_SEP':\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Abril 2024/6etmrenvironmentobserved - AQ_SEP-data-2024-04-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Junio 2024/6etmrenvironmentobserved - AQ_SEP, activa desde el 1ero de mayo-data-2024-06-14.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Agosto 2024/6etmrenvironmentobserved - AQ_SEP, activa desde el 1ero de mayo-data-2024-08-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Febrero 2024/6etmrenvironmentobserved - AQ_SEP-data-2024-02-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Diciembre 2023/6etmrenvironmentobserved - AQ_SEP-data-2023-12-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Marzo 2024/6etmrenvironmentobserved - AQ_SEP-data-2024-03-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Noviembre 2023/6etmrenvironmentobserved - AQ_SEP-data-2023-11-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Octubre 2023/6etmrenvironmentobserved - AQ_SEP-data-2023-10-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Enero 2024/6etmrenvironmentobserved - AQ_SEP-data-2024-01-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Agosto 2023/6-etmrenvironmentobserved - AQ_SEP-data-2023-08-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Septiembre 2023/6etmrenvironmentobserved - AQ_SEP-data-2023-09-14.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Mayo 2024/6etmrenvironmentobserved - AQ_SEP-data-2024-05-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Julio 2023/6-etmrenvironmentobserved-AQ_SEP-01.csv\n"
     ]
    }
   ],
   "source": [
    "# Imprimir las listas archivos AQ_SEP\n",
    "print(\"Archivos con 'AQ_SEP':\")\n",
    "for archivo in lista_aq_sep:\n",
    "    print(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivos con 'AirQualityUnit01':\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Abril 2024/7etmrairqualityobserved - AirQualityUnit01-data-2024-04-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Junio 2024/7etmrairqualityobserved - AirQualityUnit01-data-2024-06-14.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Julio 2024/7etmrairqualityobserved - AirQualityUnit01-data-2024-07-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Agosto 2024/7etmrairqualityobserved - AirQualityUnit01-data-2024-08-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Febrero 2024/7etmrairqualityobserved - AirQualityUnit01-data-2024-02-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Diciembre 2023/7etmrairqualityobserved - AirQualityUnit01-data-2023-12-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Marzo 2024/7etmrairqualityobserved - AirQualityUnit01-data-2024-03-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Noviembre 2023/7etmrairqualityobserved - AirQualityUnit01-data-2023-11-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Octubre 2023/7etmrairqualityobserved - AirQualityUnit01-data-2023-10-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Enero 2024/7etmrairqualityobserved - AirQualityUnit01-data-2024-01-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Agosto 2023/7-etmrairqualityobserved - AirQualityUnit01-data-2023-08-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Septiembre 2023/7etmrairqualityobserved - AirQualityUnit01-data-2023-09-14.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Mayo 2024/7etmrairqualityobserved - AirQualityUnit01-data-2024-05-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Julio 2023/7-etmrairqualityobserved-AirQualityUnit01-01.csv\n"
     ]
    }
   ],
   "source": [
    "# Imprimir las listas archivos AirQualityUnit01\n",
    "print(\"\\nArchivos con 'AirQualityUnit01':\")\n",
    "for archivo in lista_airqualityunit01:\n",
    "    print(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivos con 'AirQualityUnit02':\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Abril 2024/8etmrairqualityobserved - AirQualityUnit02-data-2024-04-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Junio 2024/8etmrairqualityobserved - AirQualityUnit02-data-2024-06-14.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Agosto 2024/8etmrairqualityobserved - AirQualityUnit02-data-2024-08-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Febrero 2024/8etmrairqualityobserved - AirQualityUnit02-data-2024-02-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Diciembre 2023/8etmrairqualityobserved - AirQualityUnit02-data-2023-12-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Marzo 2024/8etmrairqualityobserved - AirQualityUnit02-data-2024-03-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Noviembre 2023/8etmrairqualityobserved - AirQualityUnit02-data-2023-11-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Octubre 2023/8etmrairqualityobserved - AirQualityUnit02-data-2023-10-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Enero 2024/8etmrairqualityobserved - AirQualityUnit02-data-2024-01-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Agosto 2023/8-etmrairqualityobserved - AirQualityUnit02-data-2023-08-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Septiembre 2023/8etmrairqualityobserved - AirQualityUnit02-data-2023-09-14.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Mayo 2024/8etmrairqualityobserved - AirQualityUnit02-data-2024-05-15.csv\n",
      "/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/datos/DATOS/Julio 2023/8-etmrairqualityobserved-AirQualityUnit02-01.csv\n"
     ]
    }
   ],
   "source": [
    "# Imprimir las listas archivos AirQualityUnit02\n",
    "print(\"\\nArchivos con 'AirQualityUnit02':\")\n",
    "for archivo in lista_airqualityunit02:\n",
    "    print(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_separator_simple(file_path, sample_size=1024):\n",
    "    \"\"\"\n",
    "    Detecta el separador de un archivo CSV leyendo una muestra del archivo.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Ruta del archivo CSV.\n",
    "        sample_size (int, optional): Número de bytes a leer para el análisis. Por defecto es 1024.\n",
    "\n",
    "    Returns:\n",
    "        str: El caracter delimitador detectado o None si no se pudo detectar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            sample = f.read(sample_size)\n",
    "        dialect = csv.Sniffer().sniff(sample)\n",
    "        return dialect.delimiter\n",
    "    except Exception as e:\n",
    "        print(f\"Error al detectar el separador: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_correctly(path):\n",
    "    # Leer el archivo como texto\n",
    "    raw_df = spark.read.text(path)\n",
    "    # Obtener la primera línea\n",
    "    first_line = raw_df.first()[0]\n",
    "    separator = detect_separator_simple(path)\n",
    "    \n",
    "    if first_line and isinstance(first_line, str) and first_line.startswith(\"sep=\"):\n",
    "        # Omitir la primera línea usando zipWithIndex para mantener el orden\n",
    "        lines_rdd = raw_df.rdd.zipWithIndex() \\\n",
    "                        .filter(lambda row_index: row_index[1] > 0) \\\n",
    "                        .map(lambda row_index: row_index[0][0])\n",
    "        \n",
    "        # Leer el CSV a partir del RDD de líneas\n",
    "        df = spark.read.option(\"header\", \"true\") \\\n",
    "                       .option(\"inferSchema\", \"true\") \\\n",
    "                       .option(\"escape\", '\"') \\\n",
    "                       .option(\"quote\", '\"') \\\n",
    "                       .option(\"sep\", separator) \\\n",
    "                       .csv(lines_rdd)\n",
    "    else:\n",
    "        # Leer el CSV normalmente desde la ruta\n",
    "        df = spark.read.option(\"header\", \"true\") \\\n",
    "                       .option(\"inferSchema\", \"true\") \\\n",
    "                       .option(\"escape\", '\"') \\\n",
    "                       .option(\"quote\", '\"') \\\n",
    "                       .option(\"sep\", separator) \\\n",
    "                       .csv(path)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_LIST_AQ_SEP = [load_csv_correctly(str(path)) for path in lista_aq_sep]\n",
    "DF_LIST_AQ_01 = [load_csv_correctly(str(path)) for path in lista_airqualityunit01]\n",
    "DF_LIST_AQ_02 = [load_csv_correctly(str(path)) for path in lista_airqualityunit02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+---------+----------+-----------+------------+---------------+------------------+\n",
      "|               Time|co AQ_SEP|humidity AQ_SEP|o3 AQ_SEP|pm1 AQ_SEP|pm10 AQ_SEP|pm2_5 AQ_SEP|pressure AQ_SEP|temperature AQ_SEP|\n",
      "+-------------------+---------+---------------+---------+----------+-----------+------------+---------------+------------------+\n",
      "|2024-05-15 00:02:05|     10.1|           94.1|       -1|       0.2|        0.9|         0.8|          75332|              13.6|\n",
      "|2024-05-15 00:17:05|      9.0|           95.3|       -1|       0.3|        0.4|         0.4|          75316|              13.6|\n",
      "|2024-05-15 00:32:05|      9.7|           95.3|       -1|       0.3|        1.0|         0.9|          75297|              13.5|\n",
      "|2024-05-15 00:47:06|      8.6|           95.0|       -1|       0.2|        0.2|         0.2|          75287|              13.5|\n",
      "|2024-05-15 01:02:07|      7.5|           96.3|       -1|       0.1|        0.2|         0.2|          75280|              13.0|\n",
      "|2024-05-15 01:17:08|      6.8|           95.5|       -1|       0.1|        0.1|         0.1|          75271|              13.0|\n",
      "|2024-05-15 01:32:08|      6.0|           96.5|       -1|       0.2|        0.9|         0.7|          75283|              13.0|\n",
      "|2024-05-15 01:47:08|      5.9|           95.5|       -1|       0.3|        0.4|         0.4|          75269|              13.2|\n",
      "|2024-05-15 02:02:08|      5.9|           96.0|       -1|       0.1|        0.1|         0.1|          75244|              13.0|\n",
      "|2024-05-15 02:17:09|      5.8|           95.3|       -1|       0.1|        0.2|         0.2|          75245|              12.9|\n",
      "|2024-05-15 02:32:10|      5.7|           95.7|       -1|       0.2|        0.2|         0.2|          75254|              12.8|\n",
      "|2024-05-15 02:47:10|      6.0|           93.3|       -1|       0.1|        0.1|         0.1|          75258|              13.1|\n",
      "|2024-05-15 03:02:11|      6.1|           96.1|       -1|       0.2|        0.2|         0.2|          75253|              12.9|\n",
      "|2024-05-15 03:17:12|      6.5|           96.6|       -1|       0.2|        0.2|         0.2|          75240|              12.8|\n",
      "|2024-05-15 03:32:12|      6.7|           96.5|       -1|       0.1|        0.1|         0.1|          75217|              12.5|\n",
      "|2024-05-15 03:47:12|      7.2|           97.6|       -1|       0.2|        0.3|         0.3|          75235|              12.2|\n",
      "|2024-05-15 04:02:12|      6.8|           97.6|       -1|       0.1|        0.1|         0.1|          75248|              12.1|\n",
      "|2024-05-15 04:17:13|      6.4|          100.0|       -1|       0.1|        0.3|         0.3|          75263|              12.0|\n",
      "|2024-05-15 04:32:13|      6.9|           98.5|       -1|       0.2|        0.3|         0.3|          75266|              11.9|\n",
      "|2024-05-15 04:47:13|      6.9|           95.6|       -1|       0.1|        0.1|         0.1|          75277|              12.0|\n",
      "+-------------------+---------+---------------+---------+----------+-----------+------------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_LIST_AQ_SEP[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+----+----+----+-----+------+----+-----------------+----+------------+\n",
      "|            Time|       entity_id| co |co2 | o3 |pm10 |pm2_5 |pm5 |relativehumidity |so2 |temperature |\n",
      "+----------------+----------------+----+----+----+-----+------+----+-----------------+----+------------+\n",
      "|19/03/2024 22:08|AirQualityUnit01|-999|-999|-999| -999|  -999|-999|           -999.0|-999|      -998.0|\n",
      "| 01/04/2024 9:33|AirQualityUnit01|-999|-999|-999| -999|  -999|-999|           -999.0|-999|      -999.0|\n",
      "|08/04/2024 18:39|AirQualityUnit01|   2|1008|-999|   58|    44|  29|             60.3|-999|        20.3|\n",
      "|08/04/2024 18:41|AirQualityUnit01|   3|1028|-999|   56|    46|  30|             60.3|-999|        20.3|\n",
      "|08/04/2024 18:43|AirQualityUnit01|   4|1053|-999|   56|    46|  30|             60.3|-999|        20.3|\n",
      "|08/04/2024 18:45|AirQualityUnit01|   5|1090|-999|   61|    46|  28|             60.4|-999|        20.3|\n",
      "|08/04/2024 18:48|AirQualityUnit01|   6|1155|-999|   61|    45|  27|             60.5|-999|        20.3|\n",
      "|08/04/2024 18:50|AirQualityUnit01|   7|1198|-999|   61|    45|  27|             60.6|-999|        20.3|\n",
      "|08/04/2024 18:52|AirQualityUnit01|   8|1245|-999|   61|    46|  28|             60.7|-999|        20.4|\n",
      "|08/04/2024 18:54|AirQualityUnit01|   9|1158|-999|   53|    44|  28|             60.7|-999|        20.4|\n",
      "|08/04/2024 18:56|AirQualityUnit01|  10|1118|-999|   53|    44|  28|             60.7|-999|        20.4|\n",
      "|08/04/2024 19:00|AirQualityUnit01|  12|1181|-999|   52|    43|  27|              0.0|-999|         0.0|\n",
      "|08/04/2024 19:02|AirQualityUnit01|  13|1225|-999|   56|    40|  26|             60.8|-999|        20.5|\n",
      "|08/04/2024 19:09|AirQualityUnit01|   3|1238|-999|   56|    41|  25|             60.9|-999|        20.5|\n",
      "|08/04/2024 19:14|AirQualityUnit01|   5|1247|-999|   50|    41|  26|             60.9|-999|        20.5|\n",
      "|08/04/2024 19:16|AirQualityUnit01|   6|1189|-999|   50|    41|  26|             60.8|-999|        20.5|\n",
      "|08/04/2024 19:18|AirQualityUnit01|   7| 889|-999|   50|    41|  26|             60.2|-999|        20.5|\n",
      "|08/04/2024 19:20|AirQualityUnit01|   8| 829|-999|   50|    41|  26|             59.6|-999|        20.5|\n",
      "|08/04/2024 19:28|AirQualityUnit01|  12| 778|-999|   48|    33|  22|             58.8|-999|        20.4|\n",
      "|08/04/2024 19:30|AirQualityUnit01|  13| 783|-999|   52|    37|  24|             58.6|-999|        20.4|\n",
      "+----------------+----------------+----+----+----+-----+------+----+-----------------+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_LIST_AQ_01[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar los nombres de columnas\n",
    "def clean_column_names(df):\n",
    "    new_columns = [col.strip().replace(\" \", \"_\").lower() for col in df.columns]\n",
    "    return df.toDF(*new_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_LIST_AQ_SEP = [clean_column_names(df) for df in DF_LIST_AQ_SEP]\n",
    "DF_LIST_AQ_01 = [clean_column_names(df) for df in DF_LIST_AQ_01]\n",
    "DF_LIST_AQ_02 = [clean_column_names(df) for df in DF_LIST_AQ_02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame DF_LIST_AQ_SEP 0 columns: ['time', 'co_aq_sep', 'no2_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'relativehumidity_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 1 columns: ['time', 'co_aq_sep', 'humidity_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 2 columns: ['time', 'co_aq_sep', 'humidity_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 3 columns: ['time', 'co_aq_sep', 'no2_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'relativehumidity_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 4 columns: ['time', 'co_aq_sep', 'no2_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'relativehumidity_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 5 columns: ['time', 'co_aq_sep', 'no2_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'relativehumidity_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 6 columns: ['time', 'co_aq_sep', 'no2_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'relativehumidity_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 7 columns: ['time', 'co_aq_sep', 'no2_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'relativehumidity_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 8 columns: ['time', 'co_aq_sep', 'no2_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'relativehumidity_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 9 columns: ['time', 'address', 'battery', 'co', 'dateobserved', 'entity_id', 'entity_type', 'fiware_servicepath', 'location', 'location_centroid', 'no2', 'o3', 'pm1', 'pm10', 'pm2_5', 'pressure', 'relativehumidity', 'temperature', 'time_index']\n",
      "DataFrame DF_LIST_AQ_SEP 10 columns: ['time', 'entity_id', 'co', 'no2', 'o3', 'pm1', 'pm10', 'pm2_5', 'pressure', 'relativehumidity', 'temperature']\n",
      "DataFrame DF_LIST_AQ_SEP 11 columns: ['time', 'co_aq_sep', 'no2_aq_sep', 'o3_aq_sep', 'pm1_aq_sep', 'pm10_aq_sep', 'pm2_5_aq_sep', 'pressure_aq_sep', 'relativehumidity_aq_sep', 'temperature_aq_sep']\n",
      "DataFrame DF_LIST_AQ_SEP 12 columns: ['time', 'address', 'battery', 'co', 'dateobserved', 'entity_id', 'entity_type', 'fiware_servicepath', 'location', 'location_centroid', 'no2', 'o3', 'pm1', 'pm10', 'pm2_5', 'pressure', 'relativehumidity', 'temperature', 'time_index']\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(DF_LIST_AQ_SEP):\n",
    "    print(f\"DataFrame DF_LIST_AQ_SEP {i} columns: {df.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame DF_LIST_AQ_01 0 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 1 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 2 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 3 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 4 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 5 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 6 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 7 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 8 columns: ['time', 'co_airqualityunit01', 'co2_airqualityunit01', 'o3_airqualityunit01', 'pm10_airqualityunit01', 'pm2_5_airqualityunit01', 'pm5_airqualityunit01', 'relativehumidity_airqualityunit01', 'so2_airqualityunit01', 'temperature_airqualityunit01']\n",
      "DataFrame DF_LIST_AQ_01 9 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 10 columns: ['time', 'address', 'co', 'co2', 'dateobserved', 'entity_id', 'entity_type', 'fiware_servicepath', 'latitude', 'location', 'location_centroid', 'longitude', 'no2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'source', 'temperature', 'time_index']\n",
      "DataFrame DF_LIST_AQ_01 11 columns: ['time', 'entity_id', 'co2', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 12 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_01 13 columns: ['time', 'address', 'co', 'co2', 'dateobserved', 'entity_id', 'entity_type', 'fiware_servicepath', 'latitude', 'location', 'location_centroid', 'longitude', 'no2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'source', 'temperature', 'time_index']\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(DF_LIST_AQ_01):\n",
    "    print(f\"DataFrame DF_LIST_AQ_01 {i} columns: {df.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame DF_LIST_AQ_02 0 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 1 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 2 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 3 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 4 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 5 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 6 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 7 columns: ['time', 'co_airqualityunit02', 'co2_airqualityunit02', 'o3_airqualityunit02', 'pm10_airqualityunit02', 'pm2_5_airqualityunit02', 'pm5_airqualityunit02', 'relativehumidity_airqualityunit02', 'so2_airqualityunit02', 'temperature_airqualityunit02']\n",
      "DataFrame DF_LIST_AQ_02 8 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 9 columns: ['time', 'address', 'co', 'co2', 'dateobserved', 'entity_id', 'entity_type', 'fiware_servicepath', 'latitude', 'location', 'location_centroid', 'longitude', 'no2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'source', 'temperature', 'time_index']\n",
      "DataFrame DF_LIST_AQ_02 10 columns: ['time', 'entity_id', 'co', 'co2', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 11 columns: ['time', 'entity_id', 'co', 'co2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'temperature']\n",
      "DataFrame DF_LIST_AQ_02 12 columns: ['time', 'address', 'co', 'co2', 'dateobserved', 'entity_id', 'entity_type', 'fiware_servicepath', 'latitude', 'location', 'location_centroid', 'longitude', 'no2', 'o3', 'pm10', 'pm2_5', 'pm5', 'relativehumidity', 'so2', 'source', 'temperature', 'time_index']\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(DF_LIST_AQ_02):\n",
    "    print(f\"DataFrame DF_LIST_AQ_02 {i} columns: {df.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_df(df):\n",
    "    # Lista de columnas deseadas en el orden y con los nombres estándar\n",
    "    desired_order = [\"time\", \"pm2_5\", \"pm10\", \"co\", \"o3\", \"humidity\", \"temperature\"]\n",
    "    new_columns = []\n",
    "    \n",
    "    # Para cada columna deseada, buscar en el DataFrame original la primera columna que contenga la palabra clave\n",
    "    for keyword in desired_order:\n",
    "        # Buscar candidates: columnas cuyo nombre (en minúscula) contenga la palabra clave\n",
    "        candidates = [col for col in df.columns if keyword in col.lower()]\n",
    "        if candidates:\n",
    "            # Si existen varias, se toma la primera (podrías ajustar esto si necesitas otro criterio)\n",
    "            new_columns.append(F.col(candidates[0]).alias(keyword))\n",
    "        else:\n",
    "            # Si no existe la columna, se agrega una columna con valores nulos\n",
    "            new_columns.append(F.lit(None).alias(keyword))\n",
    "    \n",
    "    # Seleccionar y devolver el nuevo DataFrame con las columnas en el orden deseado\n",
    "    return df.select(*new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame DF_LIST_AQ_SEP_S 0 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2927\n",
      "DataFrame DF_LIST_AQ_SEP_S 1 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 1525\n",
      "DataFrame DF_LIST_AQ_SEP_S 2 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 1591\n",
      "DataFrame DF_LIST_AQ_SEP_S 3 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2866\n",
      "DataFrame DF_LIST_AQ_SEP_S 4 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2765\n",
      "DataFrame DF_LIST_AQ_SEP_S 5 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2657\n",
      "DataFrame DF_LIST_AQ_SEP_S 6 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2959\n",
      "DataFrame DF_LIST_AQ_SEP_S 7 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2859\n",
      "DataFrame DF_LIST_AQ_SEP_S 8 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2800\n",
      "DataFrame DF_LIST_AQ_SEP_S 9 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2766\n",
      "DataFrame DF_LIST_AQ_SEP_S 10 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2824\n",
      "DataFrame DF_LIST_AQ_SEP_S 11 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 1598\n",
      "DataFrame DF_LIST_AQ_SEP_S 12 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2035\n",
      "Total de filas en todos los DataFrames: 32172\n",
      "+-------------------+-----+----+----+---+--------+-----------+\n",
      "|               time|pm2_5|pm10|  co| o3|humidity|temperature|\n",
      "+-------------------+-----+----+----+---+--------+-----------+\n",
      "|2024-03-15 00:11:34|  0.5| 0.5|25.3|0.1|    -999|       11.5|\n",
      "|2024-03-15 00:26:34|  0.7| 0.7|23.0|0.1|    -999|       11.6|\n",
      "|2024-03-15 00:41:34|  0.7| 0.7|22.2|0.1|    -999|       11.2|\n",
      "|2024-03-15 00:56:34|  0.6| 0.6|20.4|0.1|    -999|       11.1|\n",
      "|2024-03-15 01:11:34|  0.6| 0.6|19.6|0.1|    -999|       10.6|\n",
      "|2024-03-15 01:26:34|  0.5| 0.5|19.2|0.1|    -999|       10.6|\n",
      "|2024-03-15 01:41:34|  0.7| 0.7|19.5|0.1|    -999|       10.4|\n",
      "|2024-03-15 01:56:34|  0.6| 0.6|21.2|0.1|    -999|       10.5|\n",
      "|2024-03-15 02:11:34|  0.5| 0.5|20.3|0.1|    -999|       10.1|\n",
      "|2024-03-15 02:26:34|  0.6| 0.6|19.2|0.1|    -999|        9.9|\n",
      "|2024-03-15 02:41:34|  0.5| 0.5|19.7|0.1|    -999|        9.7|\n",
      "|2024-03-15 02:56:34|  0.4| 0.4|17.7|0.1|    -999|        9.1|\n",
      "|2024-03-15 03:11:34|  0.6| 0.6|17.0|0.1|    -999|        9.1|\n",
      "|2024-03-15 03:26:34|  0.5| 0.5|19.8|0.1|    -999|        9.2|\n",
      "|2024-03-15 03:41:34|  0.5| 0.5|20.1|0.1|    -999|        9.0|\n",
      "|2024-03-15 03:56:34|  0.5| 0.5|22.5|0.1|    -999|        8.9|\n",
      "|2024-03-15 04:11:34|  0.6| 0.6|21.0|0.0|    -999|        8.7|\n",
      "|2024-03-15 04:26:34|  0.6| 0.6|21.0|0.1|    -999|        8.5|\n",
      "|2024-03-15 04:41:34|  0.5| 0.5|22.0|0.1|    -999|        8.6|\n",
      "|2024-03-15 04:56:34|  0.9| 1.1|21.7|0.1|    -999|        8.4|\n",
      "+-------------------+-----+----+----+---+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_LIST_AQ_SEP_S = [standardize_df(df) for df in DF_LIST_AQ_SEP]\n",
    "TOTAL_LIST_AQ_SEP_S = 0\n",
    "for i, df in enumerate(DF_LIST_AQ_SEP_S):\n",
    "    print(f\"DataFrame DF_LIST_AQ_SEP_S {i} columns: {df.columns} count: {df.count()}\")\n",
    "    TOTAL_LIST_AQ_SEP_S += df.count()\n",
    "print(f\"Total de filas en todos los DataFrames: {TOTAL_LIST_AQ_SEP_S}\")\n",
    "DF_LIST_AQ_SEP_S[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame DF_LIST_AQ_01_S 0 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2841\n",
      "DataFrame DF_LIST_AQ_01_S 1 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 12962\n",
      "DataFrame DF_LIST_AQ_01_S 2 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14216\n",
      "DataFrame DF_LIST_AQ_01_S 3 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14879\n",
      "DataFrame DF_LIST_AQ_01_S 4 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14376\n",
      "DataFrame DF_LIST_AQ_01_S 5 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14168\n",
      "DataFrame DF_LIST_AQ_01_S 6 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 13346\n",
      "DataFrame DF_LIST_AQ_01_S 7 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 15215\n",
      "DataFrame DF_LIST_AQ_01_S 8 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14458\n",
      "DataFrame DF_LIST_AQ_01_S 9 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 13936\n",
      "DataFrame DF_LIST_AQ_01_S 10 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 13489\n",
      "DataFrame DF_LIST_AQ_01_S 11 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 13678\n",
      "DataFrame DF_LIST_AQ_01_S 12 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14640\n",
      "DataFrame DF_LIST_AQ_01_S 13 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 9709\n",
      "Total de filas en todos los DataFrames: 181913\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "|            time|pm2_5|pm10|  co|  o3|humidity|temperature|\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "|19/03/2024 22:08| -999|-999|-999|-999|  -999.0|     -998.0|\n",
      "| 01/04/2024 9:33| -999|-999|-999|-999|  -999.0|     -999.0|\n",
      "|08/04/2024 18:39|   44|  58|   2|-999|    60.3|       20.3|\n",
      "|08/04/2024 18:41|   46|  56|   3|-999|    60.3|       20.3|\n",
      "|08/04/2024 18:43|   46|  56|   4|-999|    60.3|       20.3|\n",
      "|08/04/2024 18:45|   46|  61|   5|-999|    60.4|       20.3|\n",
      "|08/04/2024 18:48|   45|  61|   6|-999|    60.5|       20.3|\n",
      "|08/04/2024 18:50|   45|  61|   7|-999|    60.6|       20.3|\n",
      "|08/04/2024 18:52|   46|  61|   8|-999|    60.7|       20.4|\n",
      "|08/04/2024 18:54|   44|  53|   9|-999|    60.7|       20.4|\n",
      "|08/04/2024 18:56|   44|  53|  10|-999|    60.7|       20.4|\n",
      "|08/04/2024 19:00|   43|  52|  12|-999|     0.0|        0.0|\n",
      "|08/04/2024 19:02|   40|  56|  13|-999|    60.8|       20.5|\n",
      "|08/04/2024 19:09|   41|  56|   3|-999|    60.9|       20.5|\n",
      "|08/04/2024 19:14|   41|  50|   5|-999|    60.9|       20.5|\n",
      "|08/04/2024 19:16|   41|  50|   6|-999|    60.8|       20.5|\n",
      "|08/04/2024 19:18|   41|  50|   7|-999|    60.2|       20.5|\n",
      "|08/04/2024 19:20|   41|  50|   8|-999|    59.6|       20.5|\n",
      "|08/04/2024 19:28|   33|  48|  12|-999|    58.8|       20.4|\n",
      "|08/04/2024 19:30|   37|  52|  13|-999|    58.6|       20.4|\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_LIST_AQ_01_S = [standardize_df(df) for df in DF_LIST_AQ_01]\n",
    "TOTAL_LIST_AQ_01_S = 0\n",
    "for i, df in enumerate(DF_LIST_AQ_01_S):\n",
    "    print(f\"DataFrame DF_LIST_AQ_01_S {i} columns: {df.columns} count: {df.count()}\")\n",
    "    TOTAL_LIST_AQ_01_S += df.count()\n",
    "print(f\"Total de filas en todos los DataFrames: {TOTAL_LIST_AQ_01_S}\")\n",
    "DF_LIST_AQ_01_S[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame DF_LIST_AQ_02_S 0 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 2803\n",
      "DataFrame DF_LIST_AQ_02_S 1 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 6471\n",
      "DataFrame DF_LIST_AQ_02_S 2 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 3564\n",
      "DataFrame DF_LIST_AQ_02_S 3 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14385\n",
      "DataFrame DF_LIST_AQ_02_S 4 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 13991\n",
      "DataFrame DF_LIST_AQ_02_S 5 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 13471\n",
      "DataFrame DF_LIST_AQ_02_S 6 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14786\n",
      "DataFrame DF_LIST_AQ_02_S 7 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14245\n",
      "DataFrame DF_LIST_AQ_02_S 8 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14045\n",
      "DataFrame DF_LIST_AQ_02_S 9 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 13449\n",
      "DataFrame DF_LIST_AQ_02_S 10 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 13720\n",
      "DataFrame DF_LIST_AQ_02_S 11 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 14627\n",
      "DataFrame DF_LIST_AQ_02_S 12 columns: ['time', 'pm2_5', 'pm10', 'co', 'o3', 'humidity', 'temperature'] count: 8995\n",
      "Total de filas en todos los DataFrames: 148552\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "|            time|pm2_5|pm10|  co|  o3|humidity|temperature|\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "|19/03/2024 22:09| -999|-999|-999|-999|  -999.0|     -998.0|\n",
      "| 01/04/2024 9:33| -999|-999|-999|-999|  -999.0|     -999.0|\n",
      "|08/04/2024 20:18|   39|  45|   1|-999|    78.0|       19.0|\n",
      "|08/04/2024 20:20|   42|  54|   2|-999|    78.1|       19.3|\n",
      "|08/04/2024 20:46|   40|  47|   1|-999|    72.0|       20.3|\n",
      "|08/04/2024 20:48|   45|  59|   2|-999|    71.1|       20.4|\n",
      "|08/04/2024 20:53|   44|  56|   4|-999|    69.5|       20.5|\n",
      "|08/04/2024 20:55|   41|  51|   5|-999|    69.1|       20.5|\n",
      "|08/04/2024 20:57|   41|  52|   6|-999|    68.7|       20.6|\n",
      "|08/04/2024 20:59|   40|  52|   7|-999|    68.4|       20.6|\n",
      "|08/04/2024 21:05|   38|  48|  10|-999|    67.7|       20.8|\n",
      "|08/04/2024 21:07|   38|  51|  11|-999|    67.5|       20.8|\n",
      "|08/04/2024 21:11|   39|  50|  13|-999|    67.3|       20.9|\n",
      "|08/04/2024 21:16|   36|  46|  15|-999|    66.9|       21.1|\n",
      "|08/04/2024 21:20|   38|  45|  17|-999|    66.5|       21.2|\n",
      "|08/04/2024 21:24|   38|  49|  19|-999|    66.1|       21.3|\n",
      "|08/04/2024 21:26|   34|  44|  20|-999|    66.0|       21.3|\n",
      "|08/04/2024 21:28|   36|  48|  21|-999|    65.8|       21.4|\n",
      "|08/04/2024 21:30|   33|  39|  22|-999|    65.6|       21.4|\n",
      "|08/04/2024 21:32|   35|  43|  23|-999|    65.4|       21.4|\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_LIST_AQ_02_S = [standardize_df(df) for df in DF_LIST_AQ_02]\n",
    "TOTAL_LIST_AQ_02_S = 0\n",
    "for i, df in enumerate(DF_LIST_AQ_02_S):\n",
    "    print(f\"DataFrame DF_LIST_AQ_02_S {i} columns: {df.columns} count: {df.count()}\")\n",
    "    TOTAL_LIST_AQ_02_S += df.count()\n",
    "print(f\"Total de filas en todos los DataFrames: {TOTAL_LIST_AQ_02_S}\")\n",
    "DF_LIST_AQ_02_S[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas en todos los DF_AQ_SEP: 32172\n",
      "+-------------------+-----+----+----+---+--------+-----------+\n",
      "|               time|pm2_5|pm10|  co| o3|humidity|temperature|\n",
      "+-------------------+-----+----+----+---+--------+-----------+\n",
      "|2024-03-15 00:11:34|  0.5| 0.5|25.3|0.1|  -999.0|       11.5|\n",
      "|2024-03-15 00:26:34|  0.7| 0.7|23.0|0.1|  -999.0|       11.6|\n",
      "|2024-03-15 00:41:34|  0.7| 0.7|22.2|0.1|  -999.0|       11.2|\n",
      "|2024-03-15 00:56:34|  0.6| 0.6|20.4|0.1|  -999.0|       11.1|\n",
      "|2024-03-15 01:11:34|  0.6| 0.6|19.6|0.1|  -999.0|       10.6|\n",
      "|2024-03-15 01:26:34|  0.5| 0.5|19.2|0.1|  -999.0|       10.6|\n",
      "|2024-03-15 01:41:34|  0.7| 0.7|19.5|0.1|  -999.0|       10.4|\n",
      "|2024-03-15 01:56:34|  0.6| 0.6|21.2|0.1|  -999.0|       10.5|\n",
      "|2024-03-15 02:11:34|  0.5| 0.5|20.3|0.1|  -999.0|       10.1|\n",
      "|2024-03-15 02:26:34|  0.6| 0.6|19.2|0.1|  -999.0|        9.9|\n",
      "|2024-03-15 02:41:34|  0.5| 0.5|19.7|0.1|  -999.0|        9.7|\n",
      "|2024-03-15 02:56:34|  0.4| 0.4|17.7|0.1|  -999.0|        9.1|\n",
      "|2024-03-15 03:11:34|  0.6| 0.6|17.0|0.1|  -999.0|        9.1|\n",
      "|2024-03-15 03:26:34|  0.5| 0.5|19.8|0.1|  -999.0|        9.2|\n",
      "|2024-03-15 03:41:34|  0.5| 0.5|20.1|0.1|  -999.0|        9.0|\n",
      "|2024-03-15 03:56:34|  0.5| 0.5|22.5|0.1|  -999.0|        8.9|\n",
      "|2024-03-15 04:11:34|  0.6| 0.6|21.0|0.0|  -999.0|        8.7|\n",
      "|2024-03-15 04:26:34|  0.6| 0.6|21.0|0.1|  -999.0|        8.5|\n",
      "|2024-03-15 04:41:34|  0.5| 0.5|22.0|0.1|  -999.0|        8.6|\n",
      "|2024-03-15 04:56:34|  0.9| 1.1|21.7|0.1|  -999.0|        8.4|\n",
      "+-------------------+-----+----+----+---+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combinar todos los DataFrames en uno solo - DF_LIST_AQ_SEP_S\n",
    "DF_AQ_SEP = reduce(lambda df1, df2: df1.unionByName(df2), DF_LIST_AQ_SEP_S)\n",
    "print(f\"Total de filas en todos los DF_AQ_SEP: {DF_AQ_SEP.count()}\")\n",
    "DF_AQ_SEP.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas en todos los DF_AQ_1: 181913\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "|            time|pm2_5|pm10|  co|  o3|humidity|temperature|\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "|19/03/2024 22:08| -999|-999|-999|-999|  -999.0|     -998.0|\n",
      "| 01/04/2024 9:33| -999|-999|-999|-999|  -999.0|     -999.0|\n",
      "|08/04/2024 18:39|   44|  58|   2|-999|    60.3|       20.3|\n",
      "|08/04/2024 18:41|   46|  56|   3|-999|    60.3|       20.3|\n",
      "|08/04/2024 18:43|   46|  56|   4|-999|    60.3|       20.3|\n",
      "|08/04/2024 18:45|   46|  61|   5|-999|    60.4|       20.3|\n",
      "|08/04/2024 18:48|   45|  61|   6|-999|    60.5|       20.3|\n",
      "|08/04/2024 18:50|   45|  61|   7|-999|    60.6|       20.3|\n",
      "|08/04/2024 18:52|   46|  61|   8|-999|    60.7|       20.4|\n",
      "|08/04/2024 18:54|   44|  53|   9|-999|    60.7|       20.4|\n",
      "|08/04/2024 18:56|   44|  53|  10|-999|    60.7|       20.4|\n",
      "|08/04/2024 19:00|   43|  52|  12|-999|     0.0|        0.0|\n",
      "|08/04/2024 19:02|   40|  56|  13|-999|    60.8|       20.5|\n",
      "|08/04/2024 19:09|   41|  56|   3|-999|    60.9|       20.5|\n",
      "|08/04/2024 19:14|   41|  50|   5|-999|    60.9|       20.5|\n",
      "|08/04/2024 19:16|   41|  50|   6|-999|    60.8|       20.5|\n",
      "|08/04/2024 19:18|   41|  50|   7|-999|    60.2|       20.5|\n",
      "|08/04/2024 19:20|   41|  50|   8|-999|    59.6|       20.5|\n",
      "|08/04/2024 19:28|   33|  48|  12|-999|    58.8|       20.4|\n",
      "|08/04/2024 19:30|   37|  52|  13|-999|    58.6|       20.4|\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combinar todos los DataFrames en uno solo - DF_LIST_AQ_01_S\n",
    "DF_AQ_1 = reduce(lambda df1, df2: df1.unionByName(df2), DF_LIST_AQ_01_S)\n",
    "print(f\"Total de filas en todos los DF_AQ_1: {DF_AQ_1.count()}\")\n",
    "DF_AQ_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas en todos los DF_AQ_2: 148552\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "|            time|pm2_5|pm10|  co|  o3|humidity|temperature|\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "|19/03/2024 22:09| -999|-999|-999|-999|  -999.0|     -998.0|\n",
      "| 01/04/2024 9:33| -999|-999|-999|-999|  -999.0|     -999.0|\n",
      "|08/04/2024 20:18|   39|  45|   1|-999|    78.0|       19.0|\n",
      "|08/04/2024 20:20|   42|  54|   2|-999|    78.1|       19.3|\n",
      "|08/04/2024 20:46|   40|  47|   1|-999|    72.0|       20.3|\n",
      "|08/04/2024 20:48|   45|  59|   2|-999|    71.1|       20.4|\n",
      "|08/04/2024 20:53|   44|  56|   4|-999|    69.5|       20.5|\n",
      "|08/04/2024 20:55|   41|  51|   5|-999|    69.1|       20.5|\n",
      "|08/04/2024 20:57|   41|  52|   6|-999|    68.7|       20.6|\n",
      "|08/04/2024 20:59|   40|  52|   7|-999|    68.4|       20.6|\n",
      "|08/04/2024 21:05|   38|  48|  10|-999|    67.7|       20.8|\n",
      "|08/04/2024 21:07|   38|  51|  11|-999|    67.5|       20.8|\n",
      "|08/04/2024 21:11|   39|  50|  13|-999|    67.3|       20.9|\n",
      "|08/04/2024 21:16|   36|  46|  15|-999|    66.9|       21.1|\n",
      "|08/04/2024 21:20|   38|  45|  17|-999|    66.5|       21.2|\n",
      "|08/04/2024 21:24|   38|  49|  19|-999|    66.1|       21.3|\n",
      "|08/04/2024 21:26|   34|  44|  20|-999|    66.0|       21.3|\n",
      "|08/04/2024 21:28|   36|  48|  21|-999|    65.8|       21.4|\n",
      "|08/04/2024 21:30|   33|  39|  22|-999|    65.6|       21.4|\n",
      "|08/04/2024 21:32|   35|  43|  23|-999|    65.4|       21.4|\n",
      "+----------------+-----+----+----+----+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combinar todos los DataFrames en uno solo - DF_LIST_AQ_02_S\n",
    "DF_AQ_2 = reduce(lambda df1, df2: df1.unionByName(df2), DF_LIST_AQ_02_S)\n",
    "print(f\"Total de filas en todos los DF_AQ_2: {DF_AQ_2.count()}\")\n",
    "DF_AQ_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DF_AQ_SEP -> Cantidad de filas completamente null: 0\n",
      " DF_AQ_1 -> Cantidad de filas completamente null: 0\n",
      " DF_AQ_2 -> Cantidad de filas completamente null: 0\n"
     ]
    }
   ],
   "source": [
    "# Crear una condición que sea True cuando todas las columnas sean null\n",
    "\n",
    "CONDITION = reduce(lambda acc, col: acc & F.col(col).isNull(), DF_AQ_2.columns, F.lit(True))\n",
    "\n",
    "# Filtrar y contar las filas que cumplen la condición\n",
    "DF_AQ_SEP_ALL_NULL = DF_AQ_SEP.filter(CONDITION).count()\n",
    "DF_AQ_1_ALL_NULL = DF_AQ_1.filter(CONDITION).count()\n",
    "DF_AQ_2_ALL_NULL = DF_AQ_2.filter(CONDITION).count()\n",
    "\n",
    "\n",
    "print(\" DF_AQ_SEP -> Cantidad de filas completamente null:\", DF_AQ_SEP_ALL_NULL)\n",
    "print(\" DF_AQ_1 -> Cantidad de filas completamente null:\", DF_AQ_1_ALL_NULL)\n",
    "print(\" DF_AQ_2 -> Cantidad de filas completamente null:\", DF_AQ_2_ALL_NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_time_column(df):\n",
    "    \"\"\"\n",
    "    Procesa la columna 'time' de un DataFrame y crea una nueva columna 'time_format'\n",
    "    con el formato 'yyyy-MM-dd HH:mm:ss'.\n",
    "    \n",
    "    Considera varios formatos de fecha/hora:\n",
    "      - dd/MM/yyyy H:mm       (Ej: 19/03/2024 22:09 o 01/04/2024 9:33)\n",
    "      - yyyy-MM-dd H:mm:ss     (Ej: 2024-03-15 00:11:34)\n",
    "      - yyyy-MM-dd H:mm        (Ej: 2024-03-15 11:34)\n",
    "    \"\"\"\n",
    "    # Intenta convertir la columna \"time\" usando los diferentes formatos\n",
    "    df = df.withColumn(\n",
    "        \"time_ts\",\n",
    "        coalesce(\n",
    "            to_timestamp(col(\"time\"), \"dd/MM/yyyy H:mm\"),\n",
    "            to_timestamp(col(\"time\"), \"yyyy-MM-dd H:mm:ss\"),\n",
    "            to_timestamp(col(\"time\"), \"yyyy-MM-dd H:mm\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Formatea el timestamp al formato deseado y crea la nueva columna \"time_format\"\n",
    "    df = df.withColumn(\"time_format\", date_format(col(\"time_ts\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    \n",
    "    # Elimina la columna intermedia si ya no es necesaria\n",
    "    df = df.drop(\"time_ts\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se crea una funcion que estandariza las fechas y agrega una nueva columna\n",
    "DF_AQ_SEP = standardize_time_column(DF_AQ_SEP)\n",
    "DF_AQ_1   = standardize_time_column(DF_AQ_1)\n",
    "DF_AQ_2   = standardize_time_column(DF_AQ_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+----+----+---+--------+-----------+-------------------+\n",
      "|               time|pm2_5|pm10|  co| o3|humidity|temperature|        time_format|\n",
      "+-------------------+-----+----+----+---+--------+-----------+-------------------+\n",
      "|2024-03-15 00:11:34|  0.5| 0.5|25.3|0.1|  -999.0|       11.5|2024-03-15 00:11:34|\n",
      "|2024-03-15 00:26:34|  0.7| 0.7|23.0|0.1|  -999.0|       11.6|2024-03-15 00:26:34|\n",
      "|2024-03-15 00:41:34|  0.7| 0.7|22.2|0.1|  -999.0|       11.2|2024-03-15 00:41:34|\n",
      "|2024-03-15 00:56:34|  0.6| 0.6|20.4|0.1|  -999.0|       11.1|2024-03-15 00:56:34|\n",
      "|2024-03-15 01:11:34|  0.6| 0.6|19.6|0.1|  -999.0|       10.6|2024-03-15 01:11:34|\n",
      "|2024-03-15 01:26:34|  0.5| 0.5|19.2|0.1|  -999.0|       10.6|2024-03-15 01:26:34|\n",
      "|2024-03-15 01:41:34|  0.7| 0.7|19.5|0.1|  -999.0|       10.4|2024-03-15 01:41:34|\n",
      "|2024-03-15 01:56:34|  0.6| 0.6|21.2|0.1|  -999.0|       10.5|2024-03-15 01:56:34|\n",
      "|2024-03-15 02:11:34|  0.5| 0.5|20.3|0.1|  -999.0|       10.1|2024-03-15 02:11:34|\n",
      "|2024-03-15 02:26:34|  0.6| 0.6|19.2|0.1|  -999.0|        9.9|2024-03-15 02:26:34|\n",
      "|2024-03-15 02:41:34|  0.5| 0.5|19.7|0.1|  -999.0|        9.7|2024-03-15 02:41:34|\n",
      "|2024-03-15 02:56:34|  0.4| 0.4|17.7|0.1|  -999.0|        9.1|2024-03-15 02:56:34|\n",
      "|2024-03-15 03:11:34|  0.6| 0.6|17.0|0.1|  -999.0|        9.1|2024-03-15 03:11:34|\n",
      "|2024-03-15 03:26:34|  0.5| 0.5|19.8|0.1|  -999.0|        9.2|2024-03-15 03:26:34|\n",
      "|2024-03-15 03:41:34|  0.5| 0.5|20.1|0.1|  -999.0|        9.0|2024-03-15 03:41:34|\n",
      "|2024-03-15 03:56:34|  0.5| 0.5|22.5|0.1|  -999.0|        8.9|2024-03-15 03:56:34|\n",
      "|2024-03-15 04:11:34|  0.6| 0.6|21.0|0.0|  -999.0|        8.7|2024-03-15 04:11:34|\n",
      "|2024-03-15 04:26:34|  0.6| 0.6|21.0|0.1|  -999.0|        8.5|2024-03-15 04:26:34|\n",
      "|2024-03-15 04:41:34|  0.5| 0.5|22.0|0.1|  -999.0|        8.6|2024-03-15 04:41:34|\n",
      "|2024-03-15 04:56:34|  0.9| 1.1|21.7|0.1|  -999.0|        8.4|2024-03-15 04:56:34|\n",
      "+-------------------+-----+----+----+---+--------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_AQ_SEP.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----+----+----+--------+-----------+-------------------+\n",
      "|            time|pm2_5|pm10|  co|  o3|humidity|temperature|        time_format|\n",
      "+----------------+-----+----+----+----+--------+-----------+-------------------+\n",
      "|19/03/2024 22:08| -999|-999|-999|-999|  -999.0|     -998.0|2024-03-19 22:08:00|\n",
      "| 01/04/2024 9:33| -999|-999|-999|-999|  -999.0|     -999.0|2024-04-01 09:33:00|\n",
      "|08/04/2024 18:39|   44|  58|   2|-999|    60.3|       20.3|2024-04-08 18:39:00|\n",
      "|08/04/2024 18:41|   46|  56|   3|-999|    60.3|       20.3|2024-04-08 18:41:00|\n",
      "|08/04/2024 18:43|   46|  56|   4|-999|    60.3|       20.3|2024-04-08 18:43:00|\n",
      "|08/04/2024 18:45|   46|  61|   5|-999|    60.4|       20.3|2024-04-08 18:45:00|\n",
      "|08/04/2024 18:48|   45|  61|   6|-999|    60.5|       20.3|2024-04-08 18:48:00|\n",
      "|08/04/2024 18:50|   45|  61|   7|-999|    60.6|       20.3|2024-04-08 18:50:00|\n",
      "|08/04/2024 18:52|   46|  61|   8|-999|    60.7|       20.4|2024-04-08 18:52:00|\n",
      "|08/04/2024 18:54|   44|  53|   9|-999|    60.7|       20.4|2024-04-08 18:54:00|\n",
      "|08/04/2024 18:56|   44|  53|  10|-999|    60.7|       20.4|2024-04-08 18:56:00|\n",
      "|08/04/2024 19:00|   43|  52|  12|-999|     0.0|        0.0|2024-04-08 19:00:00|\n",
      "|08/04/2024 19:02|   40|  56|  13|-999|    60.8|       20.5|2024-04-08 19:02:00|\n",
      "|08/04/2024 19:09|   41|  56|   3|-999|    60.9|       20.5|2024-04-08 19:09:00|\n",
      "|08/04/2024 19:14|   41|  50|   5|-999|    60.9|       20.5|2024-04-08 19:14:00|\n",
      "|08/04/2024 19:16|   41|  50|   6|-999|    60.8|       20.5|2024-04-08 19:16:00|\n",
      "|08/04/2024 19:18|   41|  50|   7|-999|    60.2|       20.5|2024-04-08 19:18:00|\n",
      "|08/04/2024 19:20|   41|  50|   8|-999|    59.6|       20.5|2024-04-08 19:20:00|\n",
      "|08/04/2024 19:28|   33|  48|  12|-999|    58.8|       20.4|2024-04-08 19:28:00|\n",
      "|08/04/2024 19:30|   37|  52|  13|-999|    58.6|       20.4|2024-04-08 19:30:00|\n",
      "+----------------+-----+----+----+----+--------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_AQ_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----+----+----+--------+-----------+-------------------+\n",
      "|            time|pm2_5|pm10|  co|  o3|humidity|temperature|        time_format|\n",
      "+----------------+-----+----+----+----+--------+-----------+-------------------+\n",
      "|19/03/2024 22:09| -999|-999|-999|-999|  -999.0|     -998.0|2024-03-19 22:09:00|\n",
      "| 01/04/2024 9:33| -999|-999|-999|-999|  -999.0|     -999.0|2024-04-01 09:33:00|\n",
      "|08/04/2024 20:18|   39|  45|   1|-999|    78.0|       19.0|2024-04-08 20:18:00|\n",
      "|08/04/2024 20:20|   42|  54|   2|-999|    78.1|       19.3|2024-04-08 20:20:00|\n",
      "|08/04/2024 20:46|   40|  47|   1|-999|    72.0|       20.3|2024-04-08 20:46:00|\n",
      "|08/04/2024 20:48|   45|  59|   2|-999|    71.1|       20.4|2024-04-08 20:48:00|\n",
      "|08/04/2024 20:53|   44|  56|   4|-999|    69.5|       20.5|2024-04-08 20:53:00|\n",
      "|08/04/2024 20:55|   41|  51|   5|-999|    69.1|       20.5|2024-04-08 20:55:00|\n",
      "|08/04/2024 20:57|   41|  52|   6|-999|    68.7|       20.6|2024-04-08 20:57:00|\n",
      "|08/04/2024 20:59|   40|  52|   7|-999|    68.4|       20.6|2024-04-08 20:59:00|\n",
      "|08/04/2024 21:05|   38|  48|  10|-999|    67.7|       20.8|2024-04-08 21:05:00|\n",
      "|08/04/2024 21:07|   38|  51|  11|-999|    67.5|       20.8|2024-04-08 21:07:00|\n",
      "|08/04/2024 21:11|   39|  50|  13|-999|    67.3|       20.9|2024-04-08 21:11:00|\n",
      "|08/04/2024 21:16|   36|  46|  15|-999|    66.9|       21.1|2024-04-08 21:16:00|\n",
      "|08/04/2024 21:20|   38|  45|  17|-999|    66.5|       21.2|2024-04-08 21:20:00|\n",
      "|08/04/2024 21:24|   38|  49|  19|-999|    66.1|       21.3|2024-04-08 21:24:00|\n",
      "|08/04/2024 21:26|   34|  44|  20|-999|    66.0|       21.3|2024-04-08 21:26:00|\n",
      "|08/04/2024 21:28|   36|  48|  21|-999|    65.8|       21.4|2024-04-08 21:28:00|\n",
      "|08/04/2024 21:30|   33|  39|  22|-999|    65.6|       21.4|2024-04-08 21:30:00|\n",
      "|08/04/2024 21:32|   35|  43|  23|-999|    65.4|       21.4|2024-04-08 21:32:00|\n",
      "+----------------+-----+----+----+----+--------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_AQ_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "|time|pm2_5|pm10| co| o3|humidity|temperature|time_format|\n",
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "\n",
      "DF_AQ_SEP - Número de filas con time_format null: 0\n"
     ]
    }
   ],
   "source": [
    "# Filtrar las filas donde time_format es null\n",
    "df_null_time = DF_AQ_SEP.filter(col(\"time_format\").isNull())\n",
    "# Mostrar las filas filtradas\n",
    "df_null_time.show()\n",
    "# Opcional: contar el número de filas con time_format null\n",
    "null_count = DF_AQ_SEP.filter(col(\"time_format\").isNull()).count()\n",
    "print(\"DF_AQ_SEP - Número de filas con time_format null:\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "|time|pm2_5|pm10| co| o3|humidity|temperature|time_format|\n",
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 691:========================================>              (11 + 4) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_AQ_1 - Número de filas con time_format null: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filtrar las filas donde time_format es null\n",
    "df_null_time = DF_AQ_1.filter(col(\"time_format\").isNull())\n",
    "# Mostrar las filas filtradas\n",
    "df_null_time.show()\n",
    "# Opcional: contar el número de filas con time_format null\n",
    "null_count = DF_AQ_1.filter(col(\"time_format\").isNull()).count()\n",
    "print(\"DF_AQ_1 - Número de filas con time_format null:\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "|time|pm2_5|pm10| co| o3|humidity|temperature|time_format|\n",
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "+----+-----+----+---+---+--------+-----------+-----------+\n",
      "\n",
      "DF_AQ_2 - Número de filas con time_format null: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filtrar las filas donde time_format es null\n",
    "df_null_time = DF_AQ_2.filter(col(\"time_format\").isNull())\n",
    "# Mostrar las filas filtradas\n",
    "df_null_time.show()\n",
    "# Opcional: contar el número de filas con time_format null\n",
    "null_count = DF_AQ_2.filter(col(\"time_format\").isNull()).count()\n",
    "print(\"DF_AQ_2 - Número de filas con time_format null:\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#despues de verificar que la columna time_format no tiene valores nulos se procede a eliminar la columna time\n",
    "DF_AQ_SEP = DF_AQ_SEP.drop(\"time\")\n",
    "DF_AQ_1 = DF_AQ_1.drop(\"time\")\n",
    "DF_AQ_2 = DF_AQ_2.drop(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Exportar DF_AQ_SEP a CSV en la ruta especificada\n",
    "DF_AQ_SEP.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/export/DF_AQ_SEP.csv\")\n",
    "\n",
    "# Exportar DF_AQ_1 a CSV\n",
    "DF_AQ_1.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/export/DF_AQ_1.csv\")\n",
    "\n",
    "# Exportar DF_AQ_2 a CSV\n",
    "DF_AQ_2.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/home/steven-laptop/Documentos/Estudio/Proyecto QAIR/export/DF_AQ_2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_AQ_SEP = DF_AQ_SEP.withColumn(\"pm2_5\",\n",
    "    when(col(\"pm2_5\") <= -990, None).otherwise(col(\"pm2_5\"))\n",
    ")\n",
    "DF_AQ_SEP = DF_AQ_SEP.withColumn(\"pm10\",\n",
    "    when(col(\"pm10\") <= -990, None).otherwise(col(\"pm10\"))\n",
    ")\n",
    "DF_AQ_SEP = DF_AQ_SEP.withColumn(\"co\",\n",
    "    when(col(\"co\") <= -990, None).otherwise(col(\"co\"))\n",
    ")\n",
    "DF_AQ_SEP = DF_AQ_SEP.withColumn(\"o3\",\n",
    "    when(col(\"o3\") <= -990, None).otherwise(col(\"o3\"))\n",
    ")\n",
    "DF_AQ_SEP = DF_AQ_SEP.withColumn(\"humidity\",\n",
    "    when(col(\"humidity\") <= -990, None).otherwise(col(\"humidity\"))\n",
    ")\n",
    "DF_AQ_SEP = DF_AQ_SEP.withColumn(\"temperature\",\n",
    "    when(col(\"temperature\") <= -990, None).otherwise(col(\"temperature\"))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
